{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jQwVs8RG2rx",
        "outputId": "1a2e7362-9c38-4f65-b5c2-5ba934130c46"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFzIb9nj5p02"
      },
      "source": [
        "# **Report**\n",
        "Our overall goal in this report and assignment is to become used to Naive Bayes Algorithm. Naive Bayes is a simple classification algorithm that makes an assumption about the conditional independence of features. To familiarize with Naive Bayes Algoritm, we are tasked with implementing an algorithm that predicts whether an email is spam or ham and finally we will measure its performance to verify whether it works quite well in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChP089wF5qQQ"
      },
      "source": [
        "### Importing necessary libraries and methods\n",
        "Our first job, of course, is to import the libraries that will be used in the implementation of given assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ahxwcB9Hqc7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1"
      ],
      "metadata": {
        "id": "azeZzXYULDI-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc4gX13D8gfl"
      },
      "source": [
        "### Read the dataset into Pandas DataFrame\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z9cT-pAHtfT"
      },
      "source": [
        "df = pd.read_csv('/drive/My Drive/Colab Notebooks/BBM409-Assignment-3/emails.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhtCvKR0Huyr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "98426e43-c416-4155-a5eb-d67486954dd9"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: naturally irresistible your corporate...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: 4 color printing special  request add...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: do not have money , get software cds ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam\n",
              "0  Subject: naturally irresistible your corporate...     1\n",
              "1  Subject: the stock trading gunslinger  fanny i...     1\n",
              "2  Subject: unbelievable new homes made easy  im ...     1\n",
              "3  Subject: 4 color printing special  request add...     1\n",
              "4  Subject: do not have money , get software cds ...     1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spam and Ham Mail Information And Ratio Within Our Data\n",
        "\n",
        "We can see that vast majority of our data is made up of ham e-mails with around 75% majority"
      ],
      "metadata": {
        "id": "wdUHPZnHLJSm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E1TsoHsKQUm",
        "outputId": "0d946e0d-8544-4c89-e78b-291beedc4c3b"
      },
      "source": [
        "print('Sample Dataset Information:')\n",
        "print()\n",
        "print('Sample Dataset Shape:', df.shape)\n",
        "print()\n",
        "print('Sample Dataset Value Distribution:')\n",
        "print(df['spam'].value_counts(normalize=False))\n",
        "print()\n",
        "print('Sample Dataset Value Distribution Rates:')\n",
        "print(df['spam'].value_counts(normalize=True))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Dataset Information:\n",
            "\n",
            "Sample Dataset Shape: (5728, 2)\n",
            "\n",
            "Sample Dataset Value Distribution:\n",
            "0    4360\n",
            "1    1368\n",
            "Name: spam, dtype: int64\n",
            "\n",
            "Sample Dataset Value Distribution Rates:\n",
            "0    0.761173\n",
            "1    0.238827\n",
            "Name: spam, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbVCHv0Z8-5A"
      },
      "source": [
        "### Train-Test Split\n",
        "To estimate the performance of our model, we shuffled the given dataset and then splitted into two parts, 20% as the test set and 80% as the train set. We also checked whether the resulting datasets' ham/spam distributions are similar to our initial dataset, which we found out to be true."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Lww0YTSBtz"
      },
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.20, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr-3nzNHSBPv",
        "outputId": "59251346-bb41-4c41-b8e3-0e8c3a2dae79"
      },
      "source": [
        "print('Training Dataset Information:')\n",
        "print()\n",
        "print('Training Dataset Shape:', train_df.shape)\n",
        "print()\n",
        "print('Training Dataset Value Distribution:')\n",
        "print(train_df['spam'].value_counts(normalize=False))\n",
        "print()\n",
        "print('Training Dataset Value Distribution Rates:')\n",
        "print(train_df['spam'].value_counts(normalize=True))\n",
        "print()\n",
        "print(\"*\"*50)\n",
        "\n",
        "print()\n",
        "print('Test Dataset Information:')\n",
        "print()\n",
        "print('Test Dataset Shape:', test_df.shape)\n",
        "print()\n",
        "print('Test Dataset Value Distribution:')\n",
        "print(test_df['spam'].value_counts(normalize=False))\n",
        "print()\n",
        "print('Test Dataset Value Distribution Rates:')\n",
        "print(test_df['spam'].value_counts(normalize=True))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Information:\n",
            "\n",
            "Training Dataset Shape: (4582, 2)\n",
            "\n",
            "Training Dataset Value Distribution:\n",
            "0    3490\n",
            "1    1092\n",
            "Name: spam, dtype: int64\n",
            "\n",
            "Training Dataset Value Distribution Rates:\n",
            "0    0.761676\n",
            "1    0.238324\n",
            "Name: spam, dtype: float64\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Test Dataset Information:\n",
            "\n",
            "Test Dataset Shape: (1146, 2)\n",
            "\n",
            "Test Dataset Value Distribution:\n",
            "0    870\n",
            "1    276\n",
            "Name: spam, dtype: int64\n",
            "\n",
            "Test Dataset Value Distribution Rates:\n",
            "0    0.759162\n",
            "1    0.240838\n",
            "Name: spam, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzing Promising Words\n",
        "\n",
        "From the experience we got from real world life we live, we chose to analyze and evaluate the statistics of three highly suspicious words within e-mails.\n",
        "\n",
        "Those words are:\n",
        "- click\n",
        "- money\n",
        "- online"
      ],
      "metadata": {
        "id": "Ix9nQGrwM64b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_statistics_vectorizer = CountVectorizer()\n",
        "data_statistics = data_statistics_vectorizer.fit_transform(df['text'])\n",
        "\n",
        "index_of_click = data_statistics_vectorizer.vocabulary_['click']\n",
        "index_of_money = data_statistics_vectorizer.vocabulary_['money']\n",
        "index_of_online = data_statistics_vectorizer.vocabulary_['online']\n",
        "\n",
        "spam_data = data_statistics[np.array(df['spam'] == 1)]\n",
        "ham_data = data_statistics[np.array(df['spam'] == 0)]\n",
        "\n",
        "spam_count_click = spam_data[:, index_of_click].sum()\n",
        "ham_count_click = ham_data[:, index_of_click].sum()\n",
        "print(\"Number of times 'click' has been used in a spam mail:\", spam_count_click)\n",
        "print(\"Number of times 'click' has been used in a ham mail:\", ham_count_click)\n",
        "\n",
        "print()\n",
        "\n",
        "spam_count_money = spam_data[:, index_of_money].sum()\n",
        "ham_count_money = ham_data[:, index_of_money].sum()\n",
        "print(\"Number of times 'money' has been used in a spam mail:\", spam_count_money)\n",
        "print(\"Number of times 'money' has been used in a ham mail:\", ham_count_money)\n",
        "\n",
        "print()\n",
        "\n",
        "spam_count_online = spam_data[:, index_of_online].sum()\n",
        "ham_count_online = ham_data[:, index_of_online].sum()\n",
        "print(\"Number of times 'online' has been used in a spam mail:\", spam_count_online)\n",
        "print(\"Number of times 'online' has been used in a ham mail:\", ham_count_online)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQw1gdT7LwrN",
        "outputId": "c9ca81f5-404f-4a80-92b9-5ac4802365b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of times 'click' has been used in a spam mail: 531\n",
            "Number of times 'click' has been used in a ham mail: 200\n",
            "\n",
            "Number of times 'money' has been used in a spam mail: 662\n",
            "Number of times 'money' has been used in a ham mail: 113\n",
            "\n",
            "Number of times 'online' has been used in a spam mail: 345\n",
            "Number of times 'online' has been used in a ham mail: 173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above, we can easily see the overwhelming connection between spam e-mails and these three words as the difference between the amount of use of these words between spam and ham e-mails is drastic. In fact, the connection is even more profound than the result above, since we didn't take the difference in numbers between spam and ham e-mail amounts into account. If we normalize the count of those three words with the distribution of e-mail types in mind:"
      ],
      "metadata": {
        "id": "yjrCxs0LPE71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Normalized value of the times 'click' has been used in a spam mail:\", spam_count_click / spam_data.shape[0])\n",
        "print(\"Normalized value of the times 'click' has been used in a ham mail:\", ham_count_click / ham_data.shape[0])\n",
        "\n",
        "print()\n",
        "\n",
        "spam_count_money = spam_data[:, index_of_money].sum()\n",
        "ham_count_money = ham_data[:, index_of_money].sum()\n",
        "print(\"Normalized value of the times 'money' has been used in a spam mail:\", spam_count_money / spam_data.shape[0])\n",
        "print(\"Normalized value of the times 'money' has been used in a ham mail:\", ham_count_money / ham_data.shape[0])\n",
        "\n",
        "print()\n",
        "\n",
        "spam_count_online = spam_data[:, index_of_online].sum()\n",
        "ham_count_online = ham_data[:, index_of_online].sum()\n",
        "print(\"Normalized value of the times 'online' has been used in a spam mail:\", spam_count_online / spam_data.shape[0])\n",
        "print(\"Normalized value of the times 'online' has been used in a ham mail:\", ham_count_online / ham_data.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GuT2nsQQdD0",
        "outputId": "485b71a4-8ce3-4e60-8631-f7a896fd4273"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized value of the times 'click' has been used in a spam mail: 0.3881578947368421\n",
            "Normalized value of the times 'click' has been used in a ham mail: 0.045871559633027525\n",
            "\n",
            "Normalized value of the times 'money' has been used in a spam mail: 0.48391812865497075\n",
            "Normalized value of the times 'money' has been used in a ham mail: 0.025917431192660552\n",
            "\n",
            "Normalized value of the times 'online' has been used in a spam mail: 0.25219298245614036\n",
            "Normalized value of the times 'online' has been used in a ham mail: 0.03967889908256881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from above, each of these words has around ten times more importance within spam mails than ham ones. And within those spam mails, each one has between 25% to 50% repetition within spam mails (though we do not take the repetition within individual e-mails into account), an unbelievable difference in importance pointing us towards a clear connection between these words and spam mails as spammers seem to love to use these words within their mails."
      ],
      "metadata": {
        "id": "8hXC9S5tQ_Kl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2"
      ],
      "metadata": {
        "id": "xz95yVi4MVLb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu0LhbGlA4cf"
      },
      "source": [
        "### Naive Bayes Classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6Ncwr4wSnNk"
      },
      "source": [
        "class NaiveBayesClassifier:\n",
        "  \"\"\" The Naive Bayes Class where we do the majority of our calculations using Naive Bayes Algorithm \n",
        "  and its supportive utility functions \"\"\"\n",
        "\n",
        "  def __init__(self, ngram_range=(1,1), stop_words=None, vocabulary=None):\n",
        "\n",
        "    \"\"\"Constructor of our Naive Bates Algorithm where we define and initialize our class fields\"\"\"\n",
        "\n",
        "    # Parameters : \n",
        "    #   ngram_range (tuple): The tuple that decides which Bag of Words option will be used.\n",
        "    #   stop_words (list): The default is None. It takes the list of words which would be ignored. \n",
        "\n",
        "    #object of CountVectorizer\n",
        "    self.vectorizer = CountVectorizer(ngram_range=ngram_range, stop_words=stop_words, vocabulary=vocabulary)  \n",
        "    # Sparse Matrix which stores the count of occurrences of every word in the all mails.\n",
        "    self.count_matrix = None \n",
        "    # Sparse Matrix which stores the count of occurrences of every word in the spam mails.\n",
        "    self.spam_matrix = None\n",
        "    # Sparse Matrix which stores the count of occurrences of every word in the ham mails.\n",
        "    self.ham_matrix = None \n",
        "  \n",
        "  def fit(self, train_df):\n",
        "\n",
        "    \"\"\"Fit and train the given input dataframe by constructing a Naive Bayes Algorithm\"\"\"\n",
        "\n",
        "    # Parameter:\n",
        "    #   train_df (Pandas DataFrame): The dataframe that contains mails.\n",
        "\n",
        "    #Consturcts the sparse matrix which stores the count of each word occured in the train_df\n",
        "    self.count_matrix = self.vectorizer.fit_transform(train_df['text'])\n",
        "\n",
        "    #Constructs the sparse matrix which stores the count of occurrences of every word in the spam mails.\n",
        "    self.spam_matrix = self.count_matrix[np.array(train_df['spam'] == 1)]\n",
        "\n",
        "    #Constructs the sparse matrix which stores the count of occurrences of every word in the ham mails.\n",
        "    self.ham_matrix = self.count_matrix[np.array(train_df['spam'] == 0)]\n",
        "\n",
        "    \n",
        "    self.vocab_amount = len(self.vectorizer.vocabulary_) # vocabularies of train_df\n",
        "\n",
        "    \n",
        "    self.spam_probability = self.spam_matrix.shape[0] + 1 / self.count_matrix.shape[0] + 2 # stores the value of P(spam)\n",
        "    self.ham_probability = self.ham_matrix.shape[0] + 1 / self.count_matrix.shape[0] + 2 # tores the value of P(ham)\n",
        "\n",
        "    self.spam_total_word_count = self.spam_matrix.sum() # the total word count in the spam mails. \n",
        "    self.ham_total_word_count = self.ham_matrix.sum() # the total word count in the ham mails.\n",
        "\n",
        "  def _calculate_probability(self, sample_mail, calculating_spam):\n",
        "\n",
        "    \"\"\"Calculates the final probability of sample_mail\"\"\"\n",
        "\n",
        "    # Parameter:\n",
        "    #   sample_mail (Matrix): Matrix which stores the word counts of a specific mail.\n",
        "    #   calculating_spam (Bool): Indicates which conditional probability will be calculated.\n",
        "\n",
        "    # If P(sample_mail|spam) will be calculated\n",
        "    if calculating_spam == True:\n",
        "      matrix = self.spam_matrix  # the matrix of spam mails.\n",
        "      total_word_count = self.spam_total_word_count # total word count of spam mails.\n",
        "      class_probability = self.spam_probability  # P(spam) \n",
        "\n",
        "    # If P(sample_mail|ham) will be calculated  \n",
        "    else:\n",
        "      matrix = self.ham_matrix  # the matrix of ham mails.\n",
        "      total_word_count = self.ham_total_word_count # total word count of ham mails.\n",
        "      class_probability = self.ham_probability  # P(ham) \n",
        "\n",
        "    # Here we take the columns i.e. words that are inside our testing sample e-mail and sum each of their use amounts\n",
        "    word_sum_matrix = matrix[:, sample_mail.tocoo().col].sum(axis=0)\n",
        "\n",
        "    # As the resulting variable is a matrix, we transform it into a 1D array as it will be more useful\n",
        "    word_sum_array = np.squeeze(np.asarray(word_sum_matrix))\n",
        "    \n",
        "    # We add one to each of the words' amounts as we provide Laplace Smoothing\n",
        "    word_sum_array = np.add(word_sum_array, 1)\n",
        "\n",
        "    # We divide the resulting array to our total word count after adding the vocabulary amount as part of our smoothing\n",
        "    word_sum_array = np.divide(word_sum_array, total_word_count + self.vocab_amount)\n",
        "\n",
        "    # Once we get the frequencies of our words, we log each of them as a way to get their log-probabilities\n",
        "    word_sum_array = np.log(word_sum_array)\n",
        "\n",
        "    # Then, we sum them up to get our overall probability with logarthmic results\n",
        "    log_probability = word_sum_array.sum()\n",
        "\n",
        "    # Finally, we also add our overall class probability P(ham) or P(spam) to our final probability to get our desired result\n",
        "    log_probability = log_probability + np.log(class_probability)\n",
        "\n",
        "    return log_probability\n",
        "\n",
        "  def predict(self, test_df):\n",
        "\n",
        "    \"\"\"Predict and return the resulting targets of a dataset given to us as input\"\"\"\n",
        "\n",
        "    #Parameter:\n",
        "    #   test_df (Pandas DataFrame): DataFrame that stores test mails.\n",
        "\n",
        "  \n",
        "    test_count_matrix = self.vectorizer.transform(test_df['text']) #number of test mails.\n",
        "\n",
        "    predictions = np.array([]) \n",
        "    for mail in test_count_matrix:\n",
        "      # the probability of mail is spam\n",
        "      spam_or_ham = {}\n",
        "      spam_or_ham['spam'] = self._calculate_probability(mail, True)\n",
        "\n",
        "      # the probability of mail is ham\n",
        "      spam_or_ham['ham'] = self._calculate_probability(mail, False)\n",
        "\n",
        "      # stores the key of P(mail|spam) or P(mail|ham) which has the highest value\n",
        "      max_key = max(spam_or_ham,  key=spam_or_ham.get)\n",
        "\n",
        "      #appends 1 to predictions, if the mail is predicted as spam\n",
        "      if max_key == 'spam':\n",
        "        predictions = np.append(predictions, 1)\n",
        "\n",
        "      #appends 1 to predictions, if the mail is predicted as ham\n",
        "      else:\n",
        "        predictions = np.append(predictions, 0)\n",
        "      \n",
        "    #return the predictions of test_df\n",
        "    return predictions\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t36URpJW7UZX"
      },
      "source": [
        "def calculate_performance(true_results, predictions):\n",
        "  conf_matrix = confusion_matrix(true_results, predictions, labels=[1, 0])\n",
        "\n",
        "  tp = conf_matrix[0,0] #Number of True Positive\n",
        "  fp = conf_matrix[1,0] #Number of False Positive\n",
        "  tn = conf_matrix[1,1] #Number of True Negative\n",
        "  fn = conf_matrix[0,1] #Number of False Negative\n",
        "\n",
        "  #Calculations of classification metrics \n",
        "\n",
        "  accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "  precision = tp / (tp + fp)\n",
        "  recall = tp / (tp + fn)\n",
        "  f1 = (2 * recall * precision) / (recall + precision) \n",
        "\n",
        "  #Display classification metrics \n",
        "\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(\"Precision:\", precision)\n",
        "  print(\"Recall:\", recall)\n",
        "  print(\"F1:\", f1)\n",
        "  print(\"Confusion Matrix\\n\",conf_matrix)\n",
        "  print(\"*\"*50)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3"
      ],
      "metadata": {
        "id": "kVurqez5T3ST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzing Effect of the Words on Prediction\n",
        "\n",
        "Below, we will calculate the importance of individual words on the classes of spams and hams"
      ],
      "metadata": {
        "id": "VEe4WMBKUPBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We vectorize and count each individual word's use to calculate their importance later on\n",
        "vectorizer = CountVectorizer()\n",
        "all_counts_matrix = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Store different classes of documents in different variables\n",
        "spam_matrix = all_counts_matrix[np.array(df['spam'] == 1)]\n",
        "ham_matrix = all_counts_matrix[np.array(df['spam'] == 0)]\n",
        "\n",
        "# We prepare a tf-idf transformer to calculate the relative importance of words within each document\n",
        "transformer = TfidfTransformer()\n",
        "\n",
        "# Ham E-Mail word importance calculations\n",
        "\n",
        "# Fit and transform the ham e-mails' count matrix\n",
        "ham_tf_idf_matrix = transformer.fit_transform(ham_matrix)\n",
        "\n",
        "# We sum up the values within the matrix's columns i.e. unique words for each column\n",
        "# and then transform the resulting matrix into a easier to use array\n",
        "ham_vocabulary_tf_idf_values = np.squeeze(np.asarray(ham_tf_idf_matrix.sum(axis=0)))\n",
        "\n",
        "# Here, we normalize our resulting sum values to the amount of ham mails within our dataset\n",
        "# We do this to ensure the difference in the number of sample data between spam and ham mails\n",
        "# doesn't affect our statistics and analysis as we anchor them both to an identical point\n",
        "normalized_ham_tf_idf_values = ham_vocabulary_tf_idf_values / ham_matrix.shape[0]\n",
        "\n",
        "# Spam E-Mail word importance calculations\n",
        "\n",
        "# Fit and transform the spam e-mails' count matrix\n",
        "spam_tf_idf_matrix = transformer.fit_transform(spam_matrix)\n",
        "\n",
        "# We sum up the values within the matrix's columns i.e. unique words for each column\n",
        "# and then transform the resulting matrix into a easier to use array\n",
        "spam_vocabulary_tf_idf_values = np.squeeze(np.asarray(spam_tf_idf_matrix.sum(axis=0)))\n",
        "\n",
        "# Here, we normalize our resulting sum values to the amount of spam mails within our dataset\n",
        "# We do this to ensure the difference in the number of sample data between spam and ham mails\n",
        "# doesn't affect our statistics and analysis as we anchor them both to an identical point\n",
        "normalized_spam_tf_idf_values = spam_vocabulary_tf_idf_values / spam_matrix.shape[0]"
      ],
      "metadata": {
        "id": "1CfpXyafFZBC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQeq-9gOHsmT"
      },
      "source": [
        "# Ham\n",
        "\n",
        "# Firstly, we subtract the normalized values of words between ham and spam e-mails\n",
        "# We do this to ensure the words within every or most of the mails that doesn't constitute\n",
        "# meaningful data (Such as \"subject\" word that is stored within the start of every mail as a way to point at the starting point)\n",
        "# are given less importance within our current analysis as they do not affect classification of our data.\n",
        "ham_minus_spam = normalized_ham_tf_idf_values - normalized_spam_tf_idf_values\n",
        "\n",
        "# Then, we store both the 10 most important ham words, those that are having their presence affect the ham classification the most\n",
        "# and also the '10 least important ham words', those that are having their absence affect the ham classification the most\n",
        "most_important_indices = np.argpartition(ham_minus_spam, -10)[-10:]\n",
        "least_important_indices = np.argpartition(ham_minus_spam, 10)[:10]\n",
        "\n",
        "# Then, we use the indices we got to sort these words depending on their importance\n",
        "# We intentionally use indices as we can use them in multiple different arrays without question or problem\n",
        "most_important_sorting_indices = np.argsort(ham_minus_spam[most_important_indices])[::-1]\n",
        "least_important_sorting_indices = np.argsort(ham_minus_spam[least_important_indices])\n",
        "\n",
        "# Lastly for display purposes, we extract both the the most important present and absent words and their normalized tf-idf values\n",
        "strongest_present_ham_words = vectorizer.get_feature_names_out()[most_important_indices][most_important_sorting_indices]\n",
        "strongest_present_ham_word_values = ham_minus_spam[most_important_indices][most_important_sorting_indices]\n",
        "strongest_absent_ham_words = vectorizer.get_feature_names_out()[least_important_indices][least_important_sorting_indices]\n",
        "strongest_abesent_ham_word_values = ham_minus_spam[least_important_indices][least_important_sorting_indices]\n",
        "\n",
        "# Spam\n",
        "\n",
        "# In spam calculations too, we firstly subtract the normalized values of words between ham and spam e-mails\n",
        "# We do this to ensure the words within every or most of the mails that doesn't constitute\n",
        "# meaningful data (Such as \"subject\" word that is stored within the start of every mail as a way to point at the starting point)\n",
        "# are given less importance within our current analysis as they do not affect classification of our data.\n",
        "spam_minus_ham = normalized_spam_tf_idf_values - normalized_ham_tf_idf_values\n",
        "\n",
        "# Then, we use the indices we got to sort these words depending on their importance\n",
        "# We intentionally use indices as we can use them in multiple different arrays without question or problem\n",
        "most_important_indices = np.argpartition(spam_minus_ham, -10)[-10:]\n",
        "least_important_indices = np.argpartition(spam_minus_ham, 10)[:10]\n",
        "\n",
        "# Then, we use the indices we got to sort these words depending on their importance\n",
        "# We intentionally use indices as we can use them in multiple different arrays without question or problem\n",
        "most_important_sorting_indices = np.argsort(spam_minus_ham[most_important_indices])[::-1]\n",
        "least_important_sorting_indices = np.argsort(spam_minus_ham[least_important_indices])\n",
        "\n",
        "# Lastly for display purposes, we extract both the the most important present and absent words and their normalized tf-idf values\n",
        "strongest_present_spam_words = vectorizer.get_feature_names_out()[most_important_indices][most_important_sorting_indices]\n",
        "strongest_present_spam_word_values = spam_minus_ham[most_important_indices][most_important_sorting_indices]\n",
        "strongest_absent_spam_words = vectorizer.get_feature_names_out()[least_important_indices][least_important_sorting_indices]\n",
        "strongest_absent_spam_word_values = spam_minus_ham[least_important_indices][least_important_sorting_indices]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 words whose presence most strongly predicts that the mail is ham:\")\n",
        "print()\n",
        "print(\"Words \\t\\t Values\")\n",
        "print(\"-\"*50)\n",
        "for word, value in zip(strongest_present_ham_words, strongest_present_ham_word_values):\n",
        "  if len(word) < 5:\n",
        "    print(word, \" :\\t\\t\", value)\n",
        "  else:\n",
        "    print(word, \" :\\t\", value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EV25vOTLr-x",
        "outputId": "7fedd24a-a04f-4215-aada-4ea47b90f409"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 words whose presence most strongly predicts that the mail is ham:\n",
            "\n",
            "Words \t\t Values\n",
            "--------------------------------------------------\n",
            "ect  :\t\t 0.050719791225108744\n",
            "enron  :\t 0.04403856711707512\n",
            "vince  :\t 0.03694228067443453\n",
            "hou  :\t\t 0.025584879612187857\n",
            "the  :\t\t 0.025172686489140783\n",
            "kaminski  :\t 0.022724985334668095\n",
            "2000  :\t\t 0.022104536195975435\n",
            "am  :\t\t 0.017218117189881112\n",
            "pm  :\t\t 0.01610623471613469\n",
            "cc  :\t\t 0.015962551136407533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 words whose absence most strongly predicts that the mail is ham:\")\n",
        "print()\n",
        "print(\"Words \\t\\t Values\")\n",
        "print(\"-\"*50)\n",
        "for word, value in zip(strongest_absent_ham_words, strongest_abesent_ham_word_values):\n",
        "  if len(word) < 5:\n",
        "    print(word, \" :\\t\\t\", value)\n",
        "  else:\n",
        "    print(word, \" :\\t\", value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "535QyJ10Uk5J",
        "outputId": "78ac6313-68ef-4fb5-cb06-ccbfe1095ebf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 words whose absence most strongly predicts that the mail is ham:\n",
            "\n",
            "Words \t\t Values\n",
            "--------------------------------------------------\n",
            "your  :\t\t -0.033196770143117144\n",
            "software  :\t -0.017338619619152403\n",
            "website  :\t -0.016880055343645218\n",
            "adobe  :\t -0.016322406072843177\n",
            "you  :\t\t -0.0146451996239495\n",
            "click  :\t -0.014491941054072994\n",
            "money  :\t -0.013724226976983023\n",
            "save  :\t\t -0.013083805789379361\n",
            "here  :\t\t -0.012704522300950942\n",
            "business  :\t -0.012291112639000268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 words whose presence most strongly predicts that the mail is spam:\")\n",
        "print()\n",
        "print(\"Words \\t\\t Values\")\n",
        "print(\"-\"*50)\n",
        "for word, value in zip(strongest_present_spam_words, strongest_present_spam_word_values):\n",
        "  if len(word) < 5:\n",
        "    print(word, \" :\\t\\t\", value)\n",
        "  else:\n",
        "    print(word, \" :\\t\", value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM6ozP0NPih_",
        "outputId": "b914900d-734e-454c-bacb-a355b80a7d43"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 words whose presence most strongly predicts that the mail is spam:\n",
            "\n",
            "Words \t\t Values\n",
            "--------------------------------------------------\n",
            "your  :\t\t 0.033196770143117144\n",
            "software  :\t 0.017338619619152403\n",
            "website  :\t 0.016880055343645218\n",
            "adobe  :\t 0.016322406072843177\n",
            "you  :\t\t 0.0146451996239495\n",
            "click  :\t 0.014491941054072994\n",
            "money  :\t 0.013724226976983023\n",
            "save  :\t\t 0.013083805789379361\n",
            "here  :\t\t 0.012704522300950942\n",
            "business  :\t 0.012291112639000268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 words whose absence most strongly predicts that the mail is spam:\")\n",
        "print()\n",
        "print(\"Words \\t\\t Values\")\n",
        "print(\"-\"*50)\n",
        "for word, value in zip(strongest_absent_spam_words, strongest_absent_spam_word_values):\n",
        "  if len(word) < 5:\n",
        "    print(word, \" :\\t\\t\", value)\n",
        "  else:\n",
        "    print(word, \" :\\t\", value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-C8zq09f_7E",
        "outputId": "dbe05c23-0435-4bd2-9614-52d50e851d9c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 words whose absence most strongly predicts that the mail is spam:\n",
            "\n",
            "Words \t\t Values\n",
            "--------------------------------------------------\n",
            "ect  :\t\t -0.050719791225108744\n",
            "enron  :\t -0.04403856711707512\n",
            "vince  :\t -0.03694228067443453\n",
            "hou  :\t\t -0.025584879612187857\n",
            "the  :\t\t -0.025172686489140783\n",
            "kaminski  :\t -0.022724985334668095\n",
            "2000  :\t\t -0.022104536195975435\n",
            "am  :\t\t -0.017218117189881112\n",
            "pm  :\t\t -0.01610623471613469\n",
            "cc  :\t\t -0.015962551136407533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above lists of important words within our dataset, we can deduce many useful data points. Firstly, the words whose presence most strongly predicts spam and the words whose absence most strongly predicts ham are the same exact words; similarly, the words whose presence most strongly predicts ham and the words whose absence most strongly predicts ham are the same words as well. This is both understandable and predictable, as the fact of us working within binary classification (spam and ham), constitutes a word having opposite effects towards each class as they have no other option. We can even see it within the words: words like 'click', 'money' etc. and even informal speech like 'you', 'your' are logically indicative of a spam mail, and if we see an e-mail with an overwhelming amount of words like these, we would definetly see their absence in other mails as a logical proof of the new e-mail's hammicity. We can also see that the words that show an e-mail being ham are mostly formal, business speak, with abbreviations such as 'cc', 'am' or 'pm' showing a certain degree of professionalism behind them."
      ],
      "metadata": {
        "id": "UVHgs4cbhb6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Narrowing Down the Dictionary and Reimplementing Naive Bayes with The New Dictionary\n",
        "\n",
        "As we learned from the previous section, some words are vastly more important for some classes than other words, from which we can deduce that somewords are relatively unimportant for both classes, being situated in the middle section of our value rankings. As they are relatively unimportant, it is logical for us to test getting rid of them as it is possible that they may skew our results from time to time while not contributing and wasting precious resources in runtime. In accordance with this, we will try narrowing down our dictionary, reimplementing our Naive Bayes Algorithm and testing our dataset with this new arrangement. We obtained this new vocabulary and dictionary by comparing and extracting the best TF-IDF values, in a different way of saying, the best probabilities (both conditional and not conditional) among the numerous possible words and wordings."
      ],
      "metadata": {
        "id": "Uozl0NLrps3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ham_minus_spam.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux5bGToqs92v",
        "outputId": "c9ad6354-e413-46bd-d05a-6f14b0388cbf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37303,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As we have about 35000 different, unique words within our dictionary, we can narrow them down.\n",
        "# For this purpose we will chose 7500 of the most important spam words and 7500 of the most important ham words\n",
        "most_important_spam_words = np.argpartition(ham_minus_spam, -7500)[-7500:]\n",
        "most_important_ham_words = np.argpartition(spam_minus_ham, -7500)[-7500:]\n",
        "\n",
        "# Add these two word lists together to get our new dictionary and vocabulary\n",
        "most_important_words = np.append(most_important_spam_words, most_important_ham_words)\n",
        "vectorizer.get_feature_names_out()[most_important_words]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yewLBNl5cCHC",
        "outputId": "e503504e-e304-4719-ec25-e60dd710d361"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['4704', 'pervasive', 'ctc', ..., 'marhtadowns', '0000', 'zzzz'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing with normal, unnarrowed down vocabulary"
      ],
      "metadata": {
        "id": "PAEuz0V6t2iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier()\n",
        "classifier.fit(train_df)\n",
        "predictions = classifier.predict(test_df)\n",
        "\n",
        "calculate_performance(test_df['spam'], predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBoe6ZB6b4by",
        "outputId": "b727a739-5cfc-4b91-8bd1-434c12864abe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9886561954624782\n",
            "Precision: 0.9747292418772563\n",
            "Recall: 0.9782608695652174\n",
            "F1: 0.9764918625678118\n",
            "Confusion Matrix\n",
            " [[270   6]\n",
            " [  7 863]]\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing with narrowed down vocabulary"
      ],
      "metadata": {
        "id": "5TT3lvoOuMr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier(vocabulary=vectorizer.get_feature_names_out()[most_important_words])\n",
        "classifier.fit(train_df)\n",
        "predictions = classifier.predict(test_df)\n",
        "\n",
        "calculate_performance(test_df['spam'], predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA7aVlLkbw9L",
        "outputId": "8c1f4c52-916d-4bc3-f083-b241f452e0cf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9930191972076788\n",
            "Precision: 0.975177304964539\n",
            "Recall: 0.9963768115942029\n",
            "F1: 0.985663082437276\n",
            "Confusion Matrix\n",
            " [[275   1]\n",
            " [  7 863]]\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After testing our code numerous times, we concluded that narrowing down the dictionary may both increase or decrease our performance metrics at different times based on luck. But even when decreased, the decrease amount was always small enough to be negrected. Regardless, the fact that our vocabulary size and because of that our matrix size being drastically reduced, makes us come to the conclusion that the main and best drawing point and advantage of this narrowing down technique would be speeding up our code and increasing the efficency of our algorithm drastically."
      ],
      "metadata": {
        "id": "5GAt5pMkuPj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# New vocabulary size, and matrix column amount\n",
        "classifier.count_matrix.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqDT65lfusOJ",
        "outputId": "c408f018-a68b-4ca5-96d1-8822b648d086"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15000"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqDhsg9Prevf"
      },
      "source": [
        "### Analyzing the effect of the Stop words\n",
        "As a result of Naive Bayes algorithm, we obtained quite satisfactory performance measurements without removing stop words because we calculate the probability of each word independently from each other instead of eliminating the instance completely. But still, the performance of our model may be improved by removing stop words because stop words are commonly used words in a language. For this reason, stop words cannot be significant factor in deciding whether an email is spam or ham. They acts like noisy data in our dataset. Thanks to Naive Bayes Algorithm, keeping stop words in the dataset doesn't affect the performance much but, removing stop words may improve the performance. According to our test results, when we compare performance metrics, we see that performance metrics rarely decrease, but mostly improved by 0.1% to 1% when we remove stop words.  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, is the same code we used to calculate the importance of different words within our dataset, modified to work with stop word deletion."
      ],
      "metadata": {
        "id": "WLsFT210wErT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We vectorize and count each individual word's use to calculate their importance later on\n",
        "vectorizer = CountVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
        "all_counts_matrix = vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Store different classes of documents in different variables\n",
        "spam_matrix = all_counts_matrix[np.array(df['spam'] == 1)]\n",
        "ham_matrix = all_counts_matrix[np.array(df['spam'] == 0)]\n",
        "\n",
        "# We prepare a tf-idf transformer to calculate the relative importance of words within each document\n",
        "transformer = TfidfTransformer()\n",
        "\n",
        "# Ham E-Mail word importance calculations\n",
        "\n",
        "# Fit and transform the ham e-mails' count matrix\n",
        "ham_tf_idf_matrix = transformer.fit_transform(ham_matrix)\n",
        "\n",
        "# We sum up the values within the matrix's columns i.e. unique words for each column\n",
        "# and then transform the resulting matrix into a easier to use array\n",
        "ham_vocabulary_tf_idf_values = np.squeeze(np.asarray(ham_tf_idf_matrix.sum(axis=0)))\n",
        "\n",
        "# Here, we normalize our resulting sum values to the amount of ham mails within our dataset\n",
        "# We do this to ensure the difference in the number of sample data between spam and ham mails\n",
        "# doesn't affect our statistics and analysis as we anchor them both to an identical point\n",
        "normalized_ham_tf_idf_values = ham_vocabulary_tf_idf_values / classifier.ham_matrix.shape[0]\n",
        "\n",
        "# Spam E-Mail word importance calculations\n",
        "\n",
        "# Fit and transform the spam e-mails' count matrix\n",
        "spam_tf_idf_matrix = transformer.fit_transform(spam_matrix)\n",
        "\n",
        "# We sum up the values within the matrix's columns i.e. unique words for each column\n",
        "# and then transform the resulting matrix into a easier to use array\n",
        "spam_vocabulary_tf_idf_values = np.squeeze(np.asarray(spam_tf_idf_matrix.sum(axis=0)))\n",
        "\n",
        "# Here, we normalize our resulting sum values to the amount of spam mails within our dataset\n",
        "# We do this to ensure the difference in the number of sample data between spam and ham mails\n",
        "# doesn't affect our statistics and analysis as we anchor them both to an identical point\n",
        "normalized_spam_tf_idf_values = spam_vocabulary_tf_idf_values / classifier.spam_matrix.shape[0]"
      ],
      "metadata": {
        "id": "FTZCYaIjqY0q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ham\n",
        "\n",
        "# Firstly, we subtract the normalized values of words between ham and spam e-mails\n",
        "# We do this to ensure the words within every or most of the mails that doesn't constitute\n",
        "# meaningful data (Such as \"subject\" word that is stored within the start of every mail as a way to point at the starting point)\n",
        "# are given less importance within our current analysis as they do not affect classification of our data.\n",
        "ham_minus_spam = normalized_ham_tf_idf_values - normalized_spam_tf_idf_values\n",
        "\n",
        "# Then, we store both the 10 most important ham words, those that are having their presence affect the ham classification the most\n",
        "# and also the '10 least important ham words', those that are having their absence affect the ham classification the most\n",
        "most_important_indices = np.argpartition(ham_minus_spam, -10)[-10:]\n",
        "\n",
        "# Then, we use the indices we got to sort these words depending on their importance\n",
        "# We intentionally use indices as we can use them in multiple different arrays without question or problem\n",
        "most_important_sorting_indices = np.argsort(ham_minus_spam[most_important_indices])[::-1]\n",
        "\n",
        "# Lastly for display purposes, we extract both the the most important present and absent words and their normalized tf-idf values\n",
        "strongest_present_ham_words = vectorizer.get_feature_names_out()[most_important_indices][most_important_sorting_indices]\n",
        "strongest_present_ham_word_values = ham_minus_spam[most_important_indices][most_important_sorting_indices]\n",
        "\n",
        "# Spam\n",
        "\n",
        "# In spam calculations too, we firstly subtract the normalized values of words between ham and spam e-mails\n",
        "# We do this to ensure the words within every or most of the mails that doesn't constitute\n",
        "# meaningful data (Such as \"subject\" word that is stored within the start of every mail as a way to point at the starting point)\n",
        "# are given less importance within our current analysis as they do not affect classification of our data.\n",
        "spam_minus_ham = normalized_spam_tf_idf_values - normalized_ham_tf_idf_values\n",
        "\n",
        "# Then, we use the indices we got to sort these words depending on their importance\n",
        "# We intentionally use indices as we can use them in multiple different arrays without question or problem\n",
        "most_important_indices = np.argpartition(spam_minus_ham, -10)[-10:]\n",
        "\n",
        "# Then, we use the indices we got to sort these words depending on their importance\n",
        "# We intentionally use indices as we can use them in multiple different arrays without question or problem\n",
        "most_important_sorting_indices = np.argsort(spam_minus_ham[most_important_indices])[::-1]\n",
        "\n",
        "# Lastly for display purposes, we extract both the the most important present and absent words and their normalized tf-idf values\n",
        "strongest_present_spam_words = vectorizer.get_feature_names_out()[most_important_indices][most_important_sorting_indices]\n",
        "strongest_present_spam_word_values = spam_minus_ham[most_important_indices][most_important_sorting_indices]\n"
      ],
      "metadata": {
        "id": "leUJsN07qK9A"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 non-stop-words whose presence most strongly predicts that the mail is ham:\")\n",
        "print()\n",
        "print(\"Words \\t\\t Values\")\n",
        "print(\"-\"*50)\n",
        "for word, value in zip(strongest_present_ham_words, strongest_present_ham_word_values):\n",
        "  if len(word) < 5:\n",
        "    print(word, \" :\\t\\t\", value)\n",
        "  else:\n",
        "    print(word, \" :\\t\", value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMxETVrEwb6H",
        "outputId": "b2019bad-a02b-467b-f41f-68027125aed6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 non-stop-words whose presence most strongly predicts that the mail is ham:\n",
            "\n",
            "Words \t\t Values\n",
            "--------------------------------------------------\n",
            "ect  :\t\t 0.06710361588326001\n",
            "enron  :\t 0.05911483796813067\n",
            "vince  :\t 0.04980996314991822\n",
            "hou  :\t\t 0.033858681548476995\n",
            "kaminski  :\t 0.030448190247366433\n",
            "2000  :\t\t 0.029381740475496517\n",
            "research  :\t 0.021639825617346405\n",
            "pm  :\t\t 0.02146231910782674\n",
            "cc  :\t\t 0.02139030769584857\n",
            "2001  :\t\t 0.02125938257272819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"10 non-stop-words whose presence most strongly predicts that the mail is spam:\")\n",
        "print()\n",
        "print(\"Words \\t\\t Values\")\n",
        "print(\"-\"*50)\n",
        "for word, value in zip(strongest_present_spam_words, strongest_present_spam_word_values):\n",
        "  if len(word) < 5:\n",
        "    print(word, \" :\\t\\t\", value)\n",
        "  else:\n",
        "    print(word, \" :\\t\", value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taSCZbs2wcX4",
        "outputId": "900d331e-c759-41ed-bffc-81756c60c850"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 non-stop-words whose presence most strongly predicts that the mail is spam:\n",
            "\n",
            "Words \t\t Values\n",
            "--------------------------------------------------\n",
            "website  :\t 0.02419934399844579\n",
            "software  :\t 0.023269692847953893\n",
            "adobe  :\t 0.02066911745831094\n",
            "click  :\t 0.020586604815313464\n",
            "money  :\t 0.02023999238718702\n",
            "business  :\t 0.01827134422377757\n",
            "save  :\t\t 0.017850796467998642\n",
            "logo  :\t\t 0.017060108623563042\n",
            "online  :\t 0.015977863612334595\n",
            "95  :\t\t 0.015583034757577042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the lists above, we can see that some unimportant/generally-used words like \"you\", \"your\", \"am\" has been cut off from our vocabularies and lost their importance as a consequence. We can also see that some rare yet important words like 'research' has risen in importance after getting rid of our stopwords. While getting rid of stop words would definetly be generally a good thing, her we can also see some drawbacks that may arise from using general/non-specified stop-word lists as our stop words, as we can see that we lost the words like 'you' and 'your', words that were drastically important both data wise and logically as they showed us informal speech patterns of spammers originally, patterns that we now lost. But in general, the result seems to be adventageous and good for us."
      ],
      "metadata": {
        "id": "dKZ29iXDw0pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4"
      ],
      "metadata": {
        "id": "iyRxob9Vp7ki"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qitDZRU1R0Fw"
      },
      "source": [
        "### Performance Metric Calculator\n",
        "Displays the results of accuracy metrics such as Accuracy, Precision, Recall and F1 values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow7yemAuhzsn"
      },
      "source": [
        "### Calculation of Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFUDlfVZlvT1"
      },
      "source": [
        "#### Performance Measurement of Unigram Model by Keeping Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRIETmNjUEvF",
        "outputId": "3b5a1d5e-3fc9-4721-c540-e0379849d952"
      },
      "source": [
        "classifier = NaiveBayesClassifier()\n",
        "classifier.fit(train_df)\n",
        "predictions = classifier.predict(test_df)\n",
        "\n",
        "calculate_performance(test_df['spam'], predictions)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9886561954624782\n",
            "Precision: 0.9747292418772563\n",
            "Recall: 0.9782608695652174\n",
            "F1: 0.9764918625678118\n",
            "Confusion Matrix\n",
            " [[270   6]\n",
            " [  7 863]]\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEpImnrRnFsV"
      },
      "source": [
        "#### Performance Measurement of Bigram Model by Keeping Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyfgUNH35mKX",
        "outputId": "f87e59f8-59d7-4b2f-ed8a-6ad856623221"
      },
      "source": [
        "classifier = NaiveBayesClassifier(ngram_range=(2,2))\n",
        "classifier.fit(train_df)\n",
        "predictions = classifier.predict(test_df)\n",
        "\n",
        "calculate_performance(test_df['spam'], predictions)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.987783595113438\n",
            "Precision: 0.9924812030075187\n",
            "Recall: 0.9565217391304348\n",
            "F1: 0.974169741697417\n",
            "Confusion Matrix\n",
            " [[264  12]\n",
            " [  2 868]]\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmsAhYR6n1xJ"
      },
      "source": [
        "#### Performance Measurement of Unigram-Bigram Models Both by Keeping Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpZv34Rb5so1",
        "outputId": "6d40ed11-52a9-4308-814f-ca1ec4c02b56"
      },
      "source": [
        "classifier = NaiveBayesClassifier(ngram_range=(1,2))\n",
        "classifier.fit(train_df)\n",
        "predictions = classifier.predict(test_df)\n",
        "\n",
        "calculate_performance(test_df['spam'], predictions)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9921465968586387\n",
            "Precision: 0.9962825278810409\n",
            "Recall: 0.9710144927536232\n",
            "F1: 0.98348623853211\n",
            "Confusion Matrix\n",
            " [[268   8]\n",
            " [  1 869]]\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above three examples, we tested our Naive Bayes implementation with Unigram, Bigram and Unigram-Bigram-Hybrid implementations. Within our numerous tests, we have seen each different implementation return the best result at different times, showing us both the luck factor behind their efficency differences and the extreme closeness in results they return. In a plurality of the time, Hybrid implementation return a slightly better results than its parents. This is to be expected as this Hybrid, inevitably includes within itself the whole vocabulary of both Unigram and Bigram at the same time, resulting in a greater amount of data to infer about our predictions. But it also results in a drastically higher time to complete thanks to its data size. Speed wise, we can say that Unigram >>> Bigram > Hybrid, as their vocabulary and matrix sizes are in a close relation to their vocabulary and matrix sizes."
      ],
      "metadata": {
        "id": "lYxONe453S17"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDvSQMrrmySz"
      },
      "source": [
        "#### Performance Measurement of Unigram Model by Removing Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irofij6w8H91",
        "outputId": "1377ac27-fd69-4040-f271-14308f1fe633"
      },
      "source": [
        "classifier = NaiveBayesClassifier(stop_words=ENGLISH_STOP_WORDS)\n",
        "classifier.fit(train_df)\n",
        "predictions = classifier.predict(test_df)\n",
        "\n",
        "calculate_performance(test_df['spam'], predictions)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9912739965095986\n",
            "Precision: 0.9854014598540146\n",
            "Recall: 0.9782608695652174\n",
            "F1: 0.9818181818181817\n",
            "Confusion Matrix\n",
            " [[270   6]\n",
            " [  4 866]]\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9ZkpBU8nyYt"
      },
      "source": [
        "#### Performance Measurement of Bigram Model by Removing Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frCFiPzH8Rwl",
        "outputId": "d6f007c5-c997-44a2-9fae-1172acc86be0"
      },
      "source": [
        "classifier = NaiveBayesClassifier(ngram_range=(2,2), stop_words=ENGLISH_STOP_WORDS)\n",
        "classifier.fit(train_df)\n",
        "predictions = classifier.predict(test_df)\n",
        "\n",
        "calculate_performance(test_df['spam'], predictions)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.987783595113438\n",
            "Precision: 0.9888059701492538\n",
            "Recall: 0.9601449275362319\n",
            "F1: 0.974264705882353\n",
            "Confusion Matrix\n",
            " [[265  11]\n",
            " [  3 867]]\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zmjQmk4oVEc"
      },
      "source": [
        "#### Performance Measurement of Unigram-Bigram Models Both by Removing Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g32t1-W8TXG",
        "outputId": "be6d01fa-566a-46e7-9d53-8c9546367df8"
      },
      "source": [
        "classifier = NaiveBayesClassifier(ngram_range=(1,2), stop_words=ENGLISH_STOP_WORDS)\n",
        "classifier.fit(train_df)\n",
        "predictions = classifier.predict(test_df)\n",
        "\n",
        "calculate_performance(test_df['spam'], predictions)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9912739965095986\n",
            "Precision: 0.996268656716418\n",
            "Recall: 0.967391304347826\n",
            "F1: 0.9816176470588235\n",
            "Confusion Matrix\n",
            " [[267   9]\n",
            " [  1 869]]\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just from the above examples and from the numerous tests we have done until now. We can say that the results given by the above three stop-wordless testings' relations to one another are identical to the relations between tests that we did above with stop-words. We can understand that the relations between Unigram, Bigram and Hybrid implementations are identical regardless of stop-word deletion. If we compare the above stop-wordless examples with their implementation counterparts higher above, we can clearly see that there is an overall increase in efficiency and predictive capacity when deleting stop-words. While, rarely, time to time, the deletion of stop-words result in a decrease of accuracy and F1 score, on average, we clearly see a trend of increase in efficency when stop-words are deleted."
      ],
      "metadata": {
        "id": "bIP3h7oG52hR"
      }
    }
  ]
}